{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1BPyOI_BDWlftwPm0vRLSPbspxDPaI917","authorship_tag":"ABX9TyNnCgbtK+Ey2idbsxWvvA6C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3nLBbH-6LSa","executionInfo":{"status":"ok","timestamp":1694289276335,"user_tz":-60,"elapsed":1584,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}},"outputId":"c69ab139-86b6-44c6-efff-096f927d32be"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","import os\n","!pip install Keras-Preprocessing\n","import tensorflow as tf\n","import time\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","\n","from tqdm import tqdm_notebook, tnrange\n","from itertools import chain\n","from skimage.io import imread, imshow, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","from sklearn.model_selection import train_test_split\n","import imageio\n","\n","from keras.models import Model, load_model\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Resizing\n","from keras.layers import Lambda, RepeatVector, Reshape\n","from keras.layers import Conv2D, Conv2DTranspose\n","from keras.layers import MaxPooling2D, GlobalMaxPool2D, AveragePooling2D\n","from keras.regularizers import l2\n","#from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.optimizers import Adam\n","from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import *\n","from keras.losses import *\n","from keras import backend as keras\n","# from keras.applications.vgg16 import VGG16, preprocess_input\n","# from keras.applications.densenet import DenseNet201, DenseNet121\n","# from keras.applications import EfficientNetV2S, EfficientNetV2B1\n","from keras.utils import plot_model\n","# from keras.utils import plot_model\n","from keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","import skimage.io as io\n","# import skimage.transform as trans\n","import glob\n","from PIL import Image\n","import skimage\n","from keras.initializers import Constant\n","\n","from skimage.morphology import disk\n","from sklearn.metrics import confusion_matrix\n","from skimage.measure import label, regionprops\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import jaccard_score\n","\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, models\n","import zipfile\n","import random\n","import sys\n","\n","import skimage.io                           #Used for imshow function\n","import skimage.transform                    #Used for resize function\n","from skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\n","import matplotlib.pyplot as plt\n","from keras.layers import Concatenate, add\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","random.seed(42)\n","from keras.losses import binary_crossentropy\n","from sklearn.metrics import precision_recall_curve"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1ocJLje6byw","executionInfo":{"status":"ok","timestamp":1694289300244,"user_tz":-60,"elapsed":23920,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}},"outputId":"23a65b33-d90e-4f73-d35d-32e363c60499"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Keras-Preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m928.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n","Installing collected packages: Keras-Preprocessing\n","Successfully installed Keras-Preprocessing-1.1.2\n"]}]},{"cell_type":"code","source":["from keras import backend as K\n","from keras.losses import binary_crossentropy\n","def dice_coef(y_true, y_pred,smooth = 10):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1-dice_coef(y_true, y_pred)\n","\n","def Jaccard_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection ) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection)\n","\n","def Jaccard_coef_loss(y_true, y_pred):\n","    return (1-Jaccard_coef(y_true, y_pred))\n","\n","# def bcc_Jaccard_coef_loss(y_true, y_pred):\n","#     return (binary_crossentropy(y_true, y_pred)+(1-Jaccard_coef(y_true, y_pred)))\n","\n","#Metrices\n","from keras import backend as K\n","import tensorflow as tf\n","import keras\n","\n","def iou(y_true, y_pred, threshold=0.5):\n","    y_pred = threshold_binarize(y_pred, threshold)\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection)\n","\n","def dice_coef(y_true, y_pred, threshold=0.5):\n","    y_pred = threshold_binarize(y_pred, threshold)\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n","\n","def sensitivity(y_train, results):\n","    true_positives = K.sum(K.round(K.clip(y_train * results, 0, 1)))\n","    actual_positives = K.sum(K.round(K.clip(y_train, 0, 1)))\n","    sensitivity = true_positives / (actual_positives + K.epsilon())\n","    return sensitivity\n","\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())\n","\n","def threshold_binarize(x, threshold=0.5):\n","    ge = tf.greater_equal(x, tf.constant(threshold))\n","    y = tf.where(ge, x=tf.ones_like(x), y=tf.zeros_like(x))\n","    return y\n","\n","def DiceLoss(y_true, y_pred, smooth=1e-6):\n","    y_true, y_pred = tf.cast(y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n","    nominator = 2 * tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n","    denominator = tf.reduce_sum(y_pred ** 2) + tf.reduce_sum(y_true ** 2) + smooth\n","    result = 1 - tf.divide(nominator, denominator)\n","    return result\n","\n","\n","from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","from scipy.ndimage import distance_transform_edt as distance\n","\n","\n","def calc_dist_map(seg):\n","    res = np.zeros_like(seg)\n","    posmask = seg.astype(np.bool)\n","\n","    if posmask.any():\n","        negmask = ~posmask\n","        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n","\n","    return res\n","\n","\n","def calc_dist_map_batch(y_true):\n","    y_true_numpy = y_true.numpy()\n","    return np.array([calc_dist_map(y)\n","                     for y in y_true_numpy]).reshape(y_true.shape).astype(np.float32)\n","\n","\n","def surface_loss_keras(y_true, y_pred):\n","    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n","                                     inp=[y_true],\n","                                     Tout=tf.float32)\n","    multipled = y_pred * y_true_dist_map\n","    return K.mean(multipled)\n","\n","\n","def bcc_Jaccard_coef_loss(y_true, y_pred):\n","    return (DiceLoss(y_true, y_pred, smooth=1e-6)+(1-iou(y_true, y_pred, threshold=0.5)))\n","    #return (DiceLoss(y_true, y_pred, smooth=1e-6)+(1-iou(y_true, y_pred, threshold=0.5))+ (0.01*surface_loss_keras(y_true, y_pred)))"],"metadata":{"id":"kPtNuWnMXhHG","executionInfo":{"status":"ok","timestamp":1694289300244,"user_tz":-60,"elapsed":6,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Transfuse Net**\n"],"metadata":{"id":"7mKxS1xObLa-"}},{"cell_type":"code","source":["from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate\n","from keras import backend as K\n","\n","def cbam_block(cbam_feature, ratio=8):\n","    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n","    As described in https://arxiv.org/abs/1807.06521.\n","    \"\"\"\n","\n","    cbam_feature = channel_attention(cbam_feature, ratio)\n","    cbam_feature = spatial_attention(cbam_feature)\n","    return cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","    channel = input_feature.shape[channel_axis]\n","\n","    shared_layer_one = Dense(channel//ratio,\n","                             activation='relu',\n","                             kernel_initializer='he_normal',\n","\n","                             use_bias=True,\n","                             bias_initializer='zeros')\n","    shared_layer_two = Dense(channel,\n","                             kernel_initializer='he_normal',\n","                             use_bias=True,\n","                             bias_initializer='zeros')\n","\n","    avg_pool = GlobalAveragePooling2D()(input_feature)\n","    avg_pool = Reshape((1,1,channel))(avg_pool)\n","    assert avg_pool.shape[1:] == (1,1,channel)\n","    avg_pool = shared_layer_one(avg_pool)\n","    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n","    avg_pool = shared_layer_two(avg_pool)\n","    assert avg_pool.shape[1:] == (1,1,channel)\n","\n","    max_pool = GlobalMaxPooling2D()(input_feature)\n","    max_pool = Reshape((1,1,channel))(max_pool)\n","    assert max_pool.shape[1:] == (1,1,channel)\n","    max_pool = shared_layer_one(max_pool)\n","    assert max_pool.shape[1:] == (1,1,channel//ratio)\n","    max_pool = shared_layer_two(max_pool)\n","    assert max_pool.shape[1:] == (1,1,channel)\n","\n","    cbam_feature = Add()([avg_pool,max_pool])\n","    cbam_feature = Activation('sigmoid')(cbam_feature)\n","\n","    if K.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\n","    return multiply([input_feature, cbam_feature])\n","\n","def spatial_attention(input_feature):\n","    kernel_size = 7\n","\n","    if K.image_data_format() == \"channels_first\":\n","        channel = input_feature.shape[1]\n","        cbam_feature = Permute((2,3,1))(input_feature)\n","    else:\n","        channel = input_feature.shape[-1]\n","        cbam_feature = input_feature\n","\n","    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n","    assert avg_pool.shape[-1] == 1\n","    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n","    assert max_pool.shape[-1] == 1\n","    concat = Concatenate(axis=3)([avg_pool, max_pool])\n","    assert concat.shape[-1] == 2\n","    cbam_feature = Conv2D(filters = 1,\n","                    kernel_size=kernel_size,\n","                    strides=1,\n","                    padding='same',\n","                    activation='sigmoid',\n","                    kernel_initializer='he_normal',\n","                    use_bias=False)(concat)\n","    assert cbam_feature.shape[-1] == 1\n","\n","    if K.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\n","    return multiply([input_feature, cbam_feature])\n","\n","# def get_positional_encoding(seq_len, d_model):\n","#     positions = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n","#     div_term = tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))\n","#     sine = tf.sin(positions * div_term)\n","#     cosine = tf.cos(positions * div_term)\n","#     pos_enc = tf.concat([sine, cosine], axis=-1)\n","#     pos_enc = tf.reshape(pos_enc, (seq_len, d_model))\n","#     return pos_enc\n","\n","\n","\n","def create_transfuse_net(input_shape):\n","    # Define the input layer\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Encoder - Convolutional Blocks\n","    conv_block1 = layers.Conv2D(8, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n","    conv_block1 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block1)\n","    conv_block1 = layers.BatchNormalization()(conv_block1)\n","\n","    conv_block2 = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(conv_block1)\n","    conv_block2 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block2)\n","    conv_block2 = layers.BatchNormalization()(conv_block2)\n","\n","    conv_block3 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(conv_block2)\n","    conv_block3 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block3)\n","    conv_block3 = layers.BatchNormalization()(conv_block3)\n","\n","    # Encoder - Transformer Block\n","    transformer_block = layers.Reshape((-1, conv_block3.shape[3]))(conv_block3)\n","\n","\n","    # # Add positional encoding\n","    # seq_len = transformer_block.shape[1]\n","    # d_model = transformer_block.shape[2]\n","    # pos_enc = get_positional_encoding(seq_len, d_model)\n","    # transformer_block = tf.add(transformer_block, pos_enc)\n","\n","\n","\n","    transformer_block = layers.MultiHeadAttention(num_heads=4, key_dim=32)(transformer_block, transformer_block)\n","    transformer_block = layers.GlobalAveragePooling1D()(transformer_block)\n","    transformer_block = layers.Reshape((1, 1, transformer_block.shape[1]))(transformer_block)\n","\n","    # Tile the transformer block output to match the spatial dimensions of the convolutional block\n","    transformer_block = layers.Lambda(lambda x: tf.tile(x, [1, conv_block3.shape[1], conv_block3.shape[2], 1]))(transformer_block)\n","\n","    # Concatenate the Encoder Convolutional and Transformer blocks\n","\n","    att1 = cbam_block(transformer_block)\n","    fused_features = layers.Concatenate()([conv_block3, att1])\n","\n","    # Decoder - Upsampling Blocks\n","    decoder_block1 = layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(fused_features)\n","    att2=cbam_block(decoder_block1)\n","    decoder_block1 = layers.Concatenate()([att2, conv_block2])\n","    decoder_block1 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block1)\n","\n","    decoder_block2 = layers.Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block1)\n","\n","    att3=cbam_block(decoder_block2)\n","    decoder_block2 = layers.Concatenate()([att3, conv_block1])\n","    decoder_block2 = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block2)\n","\n","\n","    decoder_block3 = layers.Conv2DTranspose(8, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block2)\n","    decoder_block3 = layers.Conv2D(8, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block3)\n","    # Decoder - Output Block\n","    output_BV = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid',name = 'final_output1')(decoder_block3)\n","    output_OD = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid', name = 'final_output2')(decoder_block3)\n","\n","    # Create the model\n","    model = models.Model(inputs=inputs, outputs=[output_BV, output_OD])\n","\n","    return model\n","\n","# Define the input shape for binary semantic segmentation\n","input_shape = (512,512,3)  # Example input shape for RGB images\n","\n","# Create the TransFuse Encoder-Decoder model with 3 MaxPooling layers for binary semantic segmentation\n","model = create_transfuse_net(input_shape)\n"],"metadata":{"id":"40cUwmUfGVZc","executionInfo":{"status":"ok","timestamp":1694289707488,"user_tz":-60,"elapsed":1012,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# def create_transfuse_net(input_shape):\n","#     # Define the input layer\n","#     inputs = layers.Input(shape=input_shape)\n","\n","#     # Encoder - Convolutional Blocks\n","#     conv_block1 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n","#     conv_block1 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block1)\n","#     conv_block1 = layers.BatchNormalization()(conv_block1)\n","\n","#     conv_block2 = layers.Conv2D(46, kernel_size=(3, 3), padding='same', activation='relu')(conv_block1)\n","#     conv_block2 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block2)\n","#     conv_block2 = layers.BatchNormalization()(conv_block2)\n","\n","#     conv_block3 = layers.Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu')(conv_block2)\n","#     conv_block3 = layers.MaxPooling2D(pool_size=(2, 2))(conv_block3)\n","#     conv_block3 = layers.BatchNormalization()(conv_block3)\n","\n","#     # Encoder - Transformer Block\n","#     transformer_block = layers.Reshape((-1, conv_block3.shape[3]))(conv_block3)\n","#     transformer_block = layers.MultiHeadAttention(num_heads=4, key_dim=32)(transformer_block, transformer_block)\n","#     transformer_block = layers.GlobalAveragePooling1D()(transformer_block)\n","#     transformer_block = layers.Reshape((1, 1, transformer_block.shape[1]))(transformer_block)\n","\n","#     # Tile the transformer block output to match the spatial dimensions of the convolutional block\n","#     transformer_block = layers.Lambda(lambda x: tf.tile(x, [1, conv_block3.shape[1], conv_block3.shape[2], 1]))(transformer_block)\n","\n","#     # Concatenate the Encoder Convolutional and Transformer blocks\n","#     fused_features = layers.Concatenate()([conv_block3, transformer_block])\n","\n","#     # Decoder - Upsampling Blocks\n","#     decoder_block1 = layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(fused_features)\n","#     decoder_block1 = layers.Concatenate()([decoder_block1, conv_block2])\n","#     decoder_block1 = layers.Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block1)\n","\n","#     decoder_block2 = layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block1)\n","#     decoder_block2 = layers.Concatenate()([decoder_block2, conv_block1])\n","#     decoder_block2 = layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block2)\n","\n","\n","#     decoder_block3 = layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(decoder_block2)\n","#     decoder_block3 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(decoder_block3)\n","#     # Decoder - Output Block\n","#     output_BV = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid',name = 'final_output1')(decoder_block3)\n","#     output_OD = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid', name = 'final_output2')(decoder_block3)\n","\n","#     # Create the model\n","#     model = models.Model(inputs=inputs, outputs=[output_BV, output_OD])\n","\n","#     return model\n","\n","# # Define the input shape for binary semantic segmentation\n","# input_shape = (256,256, 3)  # Example input shape for RGB images\n","\n","# # Create the TransFuse Encoder-Decoder model with 3 MaxPooling layers for binary semantic segmentation\n","# model = create_transfuse_net(input_shape)\n"],"metadata":{"id":"E3aPxQ8tzvHU","executionInfo":{"status":"ok","timestamp":1694289302102,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**UNet++**"],"metadata":{"id":"ZQr8SE6PbVH5"}},{"cell_type":"code","source":["# SUPERVISION = True\n","# num_classes = 3\n","# act = \"relu\"\n","# from keras import regularizers\n","# from keras.layers import Concatenate\n","# def conv_block(inputs, filters, pool=True, drop=False):\n","#     x = Conv2D(filters, 3, padding=\"same\")(inputs) #kernel_regularizer=regularizers.l2(0.0001)\n","#     #x = BatchNormalization()(x)\n","#     x = Activation(\"relu\")(x)\n","\n","#     x = Conv2D(filters, 3, padding=\"same\")(x)\n","#     #x = BatchNormalization()(x)\n","#     x = Activation(\"relu\")(x)\n","\n","#     if pool == True and drop == True:\n","#         p = Dropout(0.5)(x)\n","#         p = MaxPool2D((2, 2))(p)\n","#         return x, p\n","#     elif pool == True and drop == False:\n","#         p = MaxPool2D((2, 2))(x)\n","#         return x, p\n","#     else:\n","#         return x\n","\n","# def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n","\n","#     x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=regularizers.l2(1e-4))(input_tensor)\n","#     #x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n","#     x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n","#     #x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n","\n","#     return x\n","\n","\n","# def UNetPlusPlus(img_rows, img_cols, color_type=3, num_class=1):\n","\n","#     nb_filter = [16,32,64,128,256]\n","\n","#     # Handle Dimension Ordering for different backends\n","#     global bn_axis\n","#     #if K.image_dim_ordering() == 'tf':\n","#     bn_axis = 3\n","#     img_input = Input(shape=(img_rows, img_cols, color_type), name='main_input')\n","#     #else:\n","#     #  bn_axis = 1\n","#     #  img_input = Input(shape=(color_type, img_rows, img_cols), name='main_input')\n","\n","#     conv1_1 = standard_unit(img_input, stage='11', nb_filter=nb_filter[0])\n","#     pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n","\n","#     conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n","#     pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n","\n","#     up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n","#     conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n","#     conv1_2 = standard_unit(conv1_2, stage='12', nb_filter=nb_filter[0])\n","\n","#     conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n","#     pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n","\n","#     up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n","#     conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n","#     conv2_2 = standard_unit(conv2_2, stage='22', nb_filter=nb_filter[1])\n","\n","#     up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n","#     conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n","#     conv1_3 = standard_unit(conv1_3, stage='13', nb_filter=nb_filter[0])\n","\n","#     conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n","#     pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n","\n","#     up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n","#     conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n","#     conv3_2 = standard_unit(conv3_2, stage='32', nb_filter=nb_filter[2])\n","\n","#     up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n","#     conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n","#     conv2_3 = standard_unit(conv2_3, stage='23', nb_filter=nb_filter[1])\n","\n","#     up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n","#     conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n","#     conv1_4 = standard_unit(conv1_4, stage='14', nb_filter=nb_filter[0])\n","\n","#     conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n","\n","#     up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n","#     conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n","#     conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n","\n","#     up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n","#     conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n","#     conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n","\n","#     up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n","#     conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n","#     conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n","\n","#     up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n","#     conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n","#     conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n","\n","#     # nestnet_output_1 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same',kernel_regularizer=regularizers.l2(1e-4))(conv1_2)\n","#     # nestnet_output_2 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv1_3)\n","#     nestnet_output_3 = Conv2D(1, (1, 1), activation='sigmoid', name='output_3', padding='same')(conv1_5)\n","#     nestnet_output_4 = Conv2D(1, (1, 1), activation='sigmoid', name='output_4',padding='same')(conv1_5)\n","\n","#     model = Model(img_input, [nestnet_output_3, nestnet_output_4])\n","#     return model\n","\n","# model = UNetPlusPlus(512,512,3, num_classes)\n","# #  loss = bcct_Jaccard_coef_loss\n","\n","\n","# model.summary()"],"metadata":{"id":"YgFKfwuSXXfs","executionInfo":{"status":"ok","timestamp":1694289302102,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Attention UNet**"],"metadata":{"id":"8q5jBdL4bhlY"}},{"cell_type":"code","source":["# # Attention module block\n","\n","# def attention_block2d(x, g, inter_channel, i, data_format='channels_last'):\n","\n","#     theta_x = Conv2D(inter_channel, [2, 2], strides=[2, 2], data_format=data_format, kernel_regularizer=regularizers.l2(1e-5))(x)\n","\n","#     phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1],dilation_rate=i, data_format=data_format, kernel_regularizer=regularizers.l2(1e-5))(g)\n","\n","#     f = LeakyReLU(alpha=0.2)(Add()([theta_x, phi_g]))\n","\n","#     psi_f = Conv2D(1, [1, 1], strides=[1, 1],dilation_rate=i, data_format=data_format, kernel_regularizer=regularizers.l2(1e-5))(f)\n","\n","#     sigm_psi_f = Activation(activation='sigmoid')(psi_f)\n","\n","#     rate = UpSampling2D(size=[2, 2])(sigm_psi_f)\n","\n","#     att_x = multiply([x, rate])\n","\n","#     return att_x\n","\n","# def res_block(x, nb_filters, strides, i):\n","\n","#     res_path = BatchNormalization()(x)\n","#     res_path = LeakyReLU(alpha=0.2)(res_path)\n","#     pool = MaxPooling2D(pool_size=(2, 2))(res_path)\n","#     res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same',dilation_rate=i, strides=strides[1], kernel_regularizer=regularizers.l2(1e-5))(pool)\n","#     res_path = BatchNormalization()(res_path)\n","#     res_path = LeakyReLU(alpha=0.2)(res_path)\n","#     res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', dilation_rate=i,strides=strides[1], kernel_regularizer=regularizers.l2(1e-5))(res_path)\n","\n","#     shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),dilation_rate=i, strides=strides[1], kernel_regularizer=regularizers.l2(1e-5))(pool)\n","#     shortcut = BatchNormalization()(shortcut)\n","\n","#     res_path = Add()([shortcut, res_path])\n","#     return res_path\n","\n","# def encoder(x):\n","#     to_decoder = []\n","\n","#     main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same',dilation_rate=(1,1), strides=(1, 1), kernel_regularizer=regularizers.l2(1e-5))(x)\n","#     main_path = BatchNormalization()(main_path)\n","#     main_path = LeakyReLU(alpha=0.2)(main_path)\n","\n","#     main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same',dilation_rate=(1,1),strides=(1, 1), kernel_regularizer=regularizers.l2(1e-5))(main_path)\n","\n","#     shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1),dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5))(x)\n","#     shortcut = BatchNormalization()(shortcut)\n","\n","#     main_path = Add()([shortcut, main_path])\n","\n","#     # first branching to decoder\n","#     to_decoder.append(main_path)\n","\n","#     main_path = res_block(main_path, [64, 64], [(2, 2), (1, 1)],(1,1))\n","#     to_decoder.append(main_path)\n","\n","#     main_path = res_block(main_path, [128,128], [(2, 2), (1, 1)],(2,2))\n","#     to_decoder.append(main_path)\n","\n","#     main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)],(4,4))\n","#     to_decoder.append(main_path)\n","\n","#     return to_decoder\n","\n","# def res_block_decoder(x, nb_filters, strides,i):\n","\n","#     res_path = BatchNormalization()(x)\n","#     res_path = LeakyReLU(alpha=0.2)(res_path)\n","#     res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', dilation_rate=i, strides=strides[1], kernel_regularizer=regularizers.l2(1e-5))(res_path)\n","#     res_path = BatchNormalization()(res_path)\n","#     res_path = LeakyReLU(alpha=0.2)(res_path)\n","#     res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', dilation_rate=i, strides=strides[1], kernel_regularizer=regularizers.l2(1e-5))(res_path)\n","\n","#     shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[1], dilation_rate=i, kernel_regularizer=regularizers.l2(1e-5))(x)\n","#     shortcut = BatchNormalization()(shortcut)\n","\n","#     res_path = Add()([shortcut, res_path])\n","\n","#     return res_path\n","# def decoder(x, from_encoder):\n","\n","#     # Layer 4\n","#     attention_path1 = attention_block2d(from_encoder[3], x, 256, (1,1), data_format='channels_last')\n","\n","#     main_path1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1),kernel_regularizer=regularizers.l2(1e-5))(x)\n","#     main_path1 = Concatenate()([main_path1,attention_path1])\n","#     main_path1 = res_block_decoder(main_path1, [256,256], [(1, 1), (1, 1)],(4,4))\n","\n","#     hc1 = three_times_sample(main_path1)\n","#     out_1 = Conv2D(filters=4, kernel_size=(1, 1), activation='softmax', name='out_1')(hc1)\n","\n","\n","#     # Layer 3\n","#     attention_path2 = attention_block2d(from_encoder[2],main_path1 ,128,(1,1),data_format='channels_last')\n","\n","#     main_path2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), dilation_rate=(1,1), padding='same', kernel_regularizer=regularizers.l2(1e-5))(main_path1)\n","#     main_path2 = Concatenate()([main_path2,attention_path2])\n","#     main_path2 = res_block_decoder(main_path2, [128, 128], [(1, 1), (1, 1)],(2,2))\n","\n","#     hc2 = two_times_sample(main_path2)\n","#     out_2 = Conv2D(filters=4, kernel_size=(1, 1), activation='softmax', name='out_2')(hc2)\n","\n","\n","#     # Layer 2\n","#     attention_path3 = attention_block2d(from_encoder[1],main_path2,64,(1,1),data_format='channels_last')\n","\n","#     main_path3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5)) (main_path2)\n","#     main_path3 = Concatenate()([main_path3,attention_path3])\n","#     main_path3 = res_block_decoder(main_path3, [64,64], [(1, 1), (1, 1)],(1,1))\n","\n","#     hc3 = one_time_sample(main_path3)\n","#     out_3 = Conv2D(filters=4, kernel_size=(1, 1), activation='softmax', name='out_3')(hc3)\n","\n","\n","#     # Layer 1\n","#     attention_path4 = attention_block2d(from_encoder[0],main_path3,32,(1,1),data_format='channels_last')\n","\n","#     main_path4 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1),kernel_regularizer=regularizers.l2(1e-5)) (main_path3)\n","#     main_path4 = Concatenate()([main_path4,attention_path4])\n","#     main_path4 = res_block_decoder(main_path4, [64, 64], [(1, 1), (1, 1)],(1,1))\n","\n","#     return main_path4, out_3, out_2, out_1\n","\n","# def three_times_sample(main_path):\n","#     hyper1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1),kernel_regularizer=regularizers.l2(1e-5)) (main_path)\n","#     hyper2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5)) (hyper1)\n","#     hyper3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5)) (hyper2)\n","#     return hyper3\n","\n","\n","# def two_times_sample(main_path):\n","#     hyper1 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5))(main_path)\n","#     hyper2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1) ,kernel_regularizer=regularizers.l2(1e-5))(hyper1)\n","#     return hyper2\n","\n","\n","# def one_time_sample(main_path):\n","#     hyper1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',dilation_rate=(1,1), kernel_regularizer=regularizers.l2(1e-5)) (main_path)\n","#     return hyper1\n","\n","\n","# def join_all_the_layers(hc1,hc2,hc3,hc4):\n","\n","#     combine1      =  Concatenate()([hc1,hc2])\n","#     combine2      =  Concatenate()([hc3,hc4])\n","#     combine_final =  Concatenate()([combine1,combine2])\n","\n","#     return combine_final\n","\n","# def aru_gd(input_shape):\n","#     inputs = Input(shape=input_shape)\n","\n","#     to_decoder = encoder(inputs)\n","\n","#     path = res_block(to_decoder[3], [256, 256], [(2, 2), (1, 1)],(8,8))\n","\n","#     final_out, out_3, out_2, out_1 = decoder(path, from_encoder=to_decoder)\n","\n","#     final_out1 = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid', name='final_output1')(final_out)\n","#     final_out2= Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid', name='final_output2')(final_out)\n","#     # return Model(inputs=inputs, outputs= [final_out, out_3, out_2, out_1])\n","#     return Model(inputs=inputs, outputs= [final_out1, final_out2])\n","\n","# from keras import regularizers\n","# input_shape = (512,512,3)\n","# model = aru_gd(input_shape)\n"],"metadata":{"id":"ZZmJVsIybY_y","executionInfo":{"status":"ok","timestamp":1694289302103,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# # model.compile(optimizer=tf.keras.optimizers.Adam(),\n","# #               loss={'conv2d_9': bcc_Jaccard_coef_loss, 'conv2d_10': bcc_Jaccard_coef_loss},\n","# #               metrics={'conv2d_9': [dice_coef, iou, sensitivity, specificity],\n","# #                        'conv2d_10': [dice_coef, iou, sensitivity, specificity]})\n","# model.compile(optimizer=tf.keras.optimizers.Adam(),\n","#               loss={'final_output1': bcc_Jaccard_coef_loss, 'final_output2': bcc_Jaccard_coef_loss},\n","#               metrics={'final_output1': [dice_coef, iou, sensitivity, specificity],\n","#                        'final_output2': [dice_coef, iou, sensitivity, specificity]})\n","\n","\n","# model.summary()"],"metadata":{"id":"ryNgtrBVWzup","executionInfo":{"status":"ok","timestamp":1694289302103,"user_tz":-60,"elapsed":12,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**UNet**"],"metadata":{"id":"mSrYgBSgbrIX"}},{"cell_type":"code","source":["# def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n","#     # first layer\n","#     x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n","#                padding=\"same\")(input_tensor)\n","#     if batchnorm:\n","#         x = BatchNormalization()(x)\n","#     x = Activation(\"relu\")(x)\n","#     # second layer\n","#     x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n","#                padding=\"same\")(x)\n","#     if batchnorm:\n","#         x = BatchNormalization()(x)\n","#     x = Activation(\"relu\")(x)\n","#     return x\n"],"metadata":{"id":"vQkXnAqhSLjS","executionInfo":{"status":"ok","timestamp":1694289302103,"user_tz":-60,"elapsed":12,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n","#     # contracting path\n","#     c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","#     p1 = MaxPooling2D((2, 2)) (c1)\n","#     p1 = Dropout(dropout*0.5)(p1)\n","\n","#     c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","#     p2 = MaxPooling2D((2, 2)) (c2)\n","#     p2 = Dropout(dropout)(p2)\n","\n","#     c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","#     p3 = MaxPooling2D((2, 2)) (c3)\n","#     p3 = Dropout(dropout)(p3)\n","\n","#     c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","#     p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n","#     p4 = Dropout(dropout)(p4)\n","\n","#     c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n","#     # expansive path\n","#     u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n","#     u6 = concatenate([u6, c4])\n","#     u6 = Dropout(dropout)(u6)\n","#     c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","\n","#     u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n","#     u7 = concatenate([u7, c3])\n","#     u7 = Dropout(dropout)(u7)\n","#     c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","\n","#     u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n","#     u8 = concatenate([u8, c2])\n","#     u8 = Dropout(dropout)(u8)\n","#     c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","\n","#     u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n","#     u9 = concatenate([u9, c1], axis=3)\n","#     u9 = Dropout(dropout)(u9)\n","#     c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","\n","#     #outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n","#     output_BV = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(c9)\n","#     output_OD = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(c9)\n","#     model = Model(inputs=[input_img], outputs=[output_BV,output_OD])\n","#     return model\n","# # Define the input shape for binary semantic segmentation\n","# input_shape = (512,512,3)  # Example input shape for RGB images\n","\n","# # Create the TransFuse Encoder-Decoder model with 3 MaxPooling layers for binary semantic segmentation\n","# #model = get_unet(input_shape)\n"],"metadata":{"id":"KRxEbqn6SNhM","executionInfo":{"status":"ok","timestamp":1694289302104,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mZQesTdOwNHW","executionInfo":{"status":"ok","timestamp":1694289302104,"user_tz":-60,"elapsed":12,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# input_img = Input((input_shape), name='img')\n","# model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n","# model.summary()"],"metadata":{"id":"EJh7CIm7SVtr","executionInfo":{"status":"ok","timestamp":1694289302105,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# # Load the pre-trained weights into the model\n","# model.load_weights('/content/drive/MyDrive/Colab_Folder/Model Weights/DRIVE/checkpoints/DRIVEattentionMTL512ep300bs4.h5')\n","\n","# #"],"metadata":{"id":"KN2C0HebdFnf","executionInfo":{"status":"ok","timestamp":1694289302105,"user_tz":-60,"elapsed":12,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#train_data ='/content/drive/MyDrive/Colab_Notebooks/DRIVE_Augmented/DRIVE_BioNet-Augmented/train' #data path\n","valid_data = '/content/drive/MyDrive/Colab_Notebooks/DRIVE_Augmented/DRIVE_BioNet-Augmented/test'"],"metadata":{"id":"sJYR1opYIh3K","executionInfo":{"status":"ok","timestamp":1694289302106,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","import os\n","import numpy as np\n","im_height=512\n","im_width=512\n","# Get and resize train images and masks\n","def get_data(path):\n","    images_paths = os.path.join(path,'images')\n","    masks_path_BV = os.path.join(path,'GT_BV')\n","    masks_path_OD = os.path.join(path,'GT_OD')\n","\n","    # images_ids = os.listdir(images_paths)\n","    # masks_ids = os.listdir(masks_paths)\n","    images_ids = sorted(os.listdir(images_paths))\n","    mask1_ids = sorted(os.listdir(masks_path_BV))\n","    mask2_ids = sorted(os.listdir(masks_path_OD))\n","\n","    X = np.zeros((len(images_ids), im_height, im_width, 3), dtype=np.float32)\n","    y1 = np.zeros((len(mask1_ids), im_height, im_width, 1), dtype=np.float32)\n","    y2 = np.zeros((len(mask2_ids), im_height, im_width, 1), dtype=np.float32)\n","    print('Getting and resizing images ... ')\n","    for n in range (len(images_ids)):\n","        # Load images\n","        img = img_to_array(load_img(os.path.join(images_paths,images_ids[n]), color_mode = \"rgb\"))\n","        x_img = resize(img, (im_height, im_width, 3), mode='constant', preserve_range=True)\n","\n","        # Load masks\n","        mask_BV = img_to_array(load_img(os.path.join(masks_path_BV,mask1_ids[n]), color_mode = \"grayscale\"))\n","        mask_BV = resize( mask_BV, (im_height, im_width, 1), mode='constant', preserve_range=True)\n","\n","        mask_OD = img_to_array(load_img(os.path.join(masks_path_OD, mask2_ids[n]), color_mode = \"grayscale\"))\n","        mask_OD = resize(mask_OD, (im_height, im_width, 1), mode='constant', preserve_range=True)\n","        # Save images\n","        X[n] = x_img/ 255\n","        y1[n] = mask_BV/ 255\n","        y2[n] = mask_OD/255\n","\n","    print('Done!')\n","    return X, [y1,y2]\n"],"metadata":{"id":"DQw1qcY6JNNW","executionInfo":{"status":"ok","timestamp":1694289302106,"user_tz":-60,"elapsed":13,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# valid_data = '/content/ISIC2018_512x512/test' #data path\n","X_test, y_test = get_data(valid_data)\n"],"metadata":{"id":"kfLXEKE1IW9U","executionInfo":{"status":"ok","timestamp":1694289334444,"user_tz":-60,"elapsed":32350,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"38947396-c535-4e38-c6d6-8775ee72bcc4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting and resizing images ... \n","Done!\n"]}]},{"cell_type":"code","source":["def evaluate_metrics(y_test, y_pred):\n","  n = y_pred.shape[0]\n","  all_F1_score = np.zeros(n)\n","  all_dice = np.zeros(n)\n","  all_jaccard = np.zeros(n)\n","  all_sensitivity = np.zeros(n)\n","  all_specificity = np.zeros(n)\n","  for i in range(n):\n","      gt, pred = y_test[i], y_pred[i]\n","      gt_flt = np.ndarray.flatten(gt)\n","      pred_flt = np.ndarray.flatten(pred)\n","\n","      precisions, recalls, thresholds = precision_recall_curve(gt_flt, pred_flt)\n","      f1 = 2*(precisions * recalls) / (precisions + recalls)\n","      max_value = np.argmax(f1)\n","      thres = thresholds[max_value]\n","      pred_mask = (pred_flt >= thres)\n","      pred_label = pred_mask*1\n","\n","      tn, fp, fn, tp = confusion_matrix(gt_flt, pred_label).ravel()\n","\n","      F1_score = tp/(tp+((0.5)*(fp+fn)))\n","      iou = tp / (tp + fp + fn)\n","      dice = 2*tp / (2*tp + fp + fn)\n","      specificity = tn / (tn + fp)\n","      recall = tp / (tp + fn)\n","\n","      all_F1_score[i] = F1_score\n","      all_dice[i] = dice\n","      all_jaccard[i] = iou\n","      all_sensitivity[i] = recall\n","      all_specificity[i] = specificity\n","\n","  print(' F1_score: {:4f}, Dice: {:4f}, Jaccard: {:4f}, Sensitivity: {:4f}, Specificity: {:4f}'.format(\n","        np.nanmean(all_F1_score), np.nanmean(all_dice), np.nanmean(all_jaccard), np.nanmean(all_sensitivity), np.nanmean(all_specificity)\n","  ))\n","  return all_F1_score, all_dice, all_jaccard, all_sensitivity, all_specificity\n"],"metadata":{"id":"yhhdBDHjeYxk","executionInfo":{"status":"ok","timestamp":1694289334445,"user_tz":-60,"elapsed":8,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["custom_objects = {\"bcc_Jaccard_coef_loss\": bcc_Jaccard_coef_loss,\"dice_coef\":dice_coef,\"iou\": iou,\"sensitivity\":sensitivity,\"specificity\":specificity}"],"metadata":{"id":"m0ioOll4wOUY","executionInfo":{"status":"ok","timestamp":1694289334445,"user_tz":-60,"elapsed":5,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model.load_weights('/content/drive/MyDrive/Colab_Folder/Model Weights/DRIVE/FINAL/Models/ModelTransCNN_300_16.h5')"],"metadata":{"id":"Zoe-dK4vyLKq","executionInfo":{"status":"error","timestamp":1694291884786,"user_tz":-60,"elapsed":326,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}},"colab":{"base_uri":"https://localhost:8080/","height":321},"outputId":"a2a03ab0-4b2b-4ff9-cbad-33ede28bf909"},"execution_count":21,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-f80573b410c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab_Folder/Model Weights/DRIVE/FINAL/Models/ModelTransCNN_300_16.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    817\u001b[0m             \u001b[0;34m\"Layer count mismatch when loading weights from file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;34mf\"Model expected {len(filtered_layers)} layers, found \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 24 layers, found 47 saved layers."]}]},{"cell_type":"code","source":["# model_path = '/content/drive/MyDrive/Colab_Folder/Model Weights/DRIVE/FINAL/POS_MTLTransCNNep300bs16.h5'\n","# model = tf.keras.models.load_model(model_path,custom_objects=custom_objects)\n","\n","#model1 = model.load('/content/drive/MyDrive/Colab_Folder/Model Weights/IOSTAR/FINAL//content/drive/MyDrive/Colab_Folder/Model Weights/DRIVE/FINAL/modelattentionUnetoriginal300_4.h5')\n","# model2 = tf.keras.models.load_model('path_to_model2.h5')\n","# model3 = tf.keras.models.load_model('path_to_model3.h5')\n","# model4 = tf.keras.models.load_model('path_to_model4.h5')\n","import timeit\n","\n","# Assuming you have some input_data ready\n","#input_data = ...  # This could be something like tf.random.normal([batch_size, input_shape])\n","test_image = load_img('/content/drive/MyDrive/Colab_Notebooks/DRIVE_Augmented/DRIVE_BioNet-Augmented/test/images/15.png', target_size=(512, 512))\n","test_image = img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","print(test_image.shape)\n","# Scale the pixel values to [0, 1] range\n","test_image = test_image / 255.\n","def predict_model1():\n","   predict_model1= model.predict(test_image, verbose=1)\n","\n","# def predict_model2():\n","#     model2.predict(input_data)\n","\n","# def predict_model3():\n","#     model3.predict(input_data)\n","\n","# def predict_model4():\n","#     model4.predict(input_data)\n","\n","time_model1 = timeit.timeit(predict_model1, number=5)  # Adjust the number as needed\n","# time_model2 = timeit.timeit(predict_model2, number=10)  # Adjust the number as needed\n","# time_model3 = timeit.timeit(predict_model3, number=10)  # Adjust the number as needed\n","# time_model4 = timeit.timeit(predict_model4, number=10)  # Adjust the number as needed\n","\n","print(f\"Model 1 Prediction Time: {time_model1:.5f} seconds\")\n","# print(f\"Model 2 Prediction Time: {time_model2:.5f} seconds\")\n","# print(f\"Model 3 Prediction Time: {time_model3:.5f} seconds\")\n","# print(f\"Model 4 Prediction Time: {time_model4:.5f} seconds\")\n"],"metadata":{"id":"42lvTG3Bw4d3","executionInfo":{"status":"aborted","timestamp":1694289334796,"user_tz":-60,"elapsed":20,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["per_model = time_model1/5\n","print(per_model)\n"],"metadata":{"id":"ZCSPIZk71qcW","executionInfo":{"status":"aborted","timestamp":1694289334796,"user_tz":-60,"elapsed":19,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert ground truth labels to binary\n","y_test_BV = (y_test[0] > 0.5).astype(np.uint8)\n","y_test_OD = (y_test[1] > 0.5).astype(np.uint8)\n","\n","start_time = time.time()\n","predictions = model.predict(X_test, batch_size=1, verbose=1)\n","\n","end_time = time.time()\n","inference_time = end_time - start_time\n","print(\"Inference Time: {:.2f} seconds\".format(inference_time))\n","inference_time_per_image = inference_time/len(X_test)\n","print(\"Inference Time per image: {:.2f} seconds\".format(inference_time_per_image ))\n"],"metadata":{"id":"PCbgGupU8q1v","executionInfo":{"status":"aborted","timestamp":1694289334797,"user_tz":-60,"elapsed":20,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert model's outputs to binary\n","predictions_BV = (predictions[0] > 0.5).astype(np.uint8)\n","predictions_OD = (predictions[1] > 0.5).astype(np.uint8)\n","\n","# Evaluate metrics for each task\n","eval_BV = evaluate_metrics(y_test_BV, predictions_BV)\n","eval_OD = evaluate_metrics(y_test_OD, predictions_OD)"],"metadata":{"id":"CNEX5AlyG0Sl","executionInfo":{"status":"aborted","timestamp":1694289334798,"user_tz":-60,"elapsed":21,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory_usage = model.count_params() * 4  # Assuming float32 data type (4 bytes per parameter)\n","print(\"Memory Usage: {:.2f} MB\".format(memory_usage / 1024 / 1024))  # Divide by 1024 twice to convert from bytes to KB, then KB to MB\n"],"metadata":{"id":"PHoiWyPn_gVj","executionInfo":{"status":"aborted","timestamp":1694289334798,"user_tz":-60,"elapsed":20,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_image = load_img('/content/drive/MyDrive/Colab_Notebooks/DRIVE_Augmented/DRIVE_BioNet-Augmented/test/images/15.png', target_size=(512, 512))\n","test_image = img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","\n","# Scale the pixel values to [0, 1] range\n","test_image = test_image / 255.\n","\n","# Use the model to predict the mask for the test image\n","\n","start_time = time.time()\n","preds_test = model.predict(test_image)\n","end_time = time.time()\n","inference_time = end_time - start_time\n","print(\"Inference Time: {:.2f} seconds\".format(inference_time))\n"],"metadata":{"id":"YVfEETBmKjmT","executionInfo":{"status":"aborted","timestamp":1694289334800,"user_tz":-60,"elapsed":21,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","fig, ax = plt.subplots(nrows=1, ncols=3)\n","ax[0].imshow(test_image[0])\n","ax[0].axis('off')\n","ax[1].imshow(np.squeeze(preds_test[0]), cmap='gray') # squeeze out unnecessary dimensions\n","ax[1].axis('off')\n","ax[2].imshow(np.squeeze(preds_test[1]), cmap='gray')\n","ax[2].axis('off')\n","\n","#fig, ax = plt.subplots(nrows=1, ncols=2)\n","#ax[0].imshow(test_image[0])\n","#ax[1].imshow(preds_test[0], cmap='gray') # you may need"],"metadata":{"id":"oOSCg-5aLi35","executionInfo":{"status":"aborted","timestamp":1694289334801,"user_tz":-60,"elapsed":22,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  !pip install keras-flops\n","  from keras_flops import get_flops\n","\n","  flops = get_flops(model)\n","  print(f\"FLOPs: {flops / 10**9:.03} G\")"],"metadata":{"id":"rdBagWW1osur","executionInfo":{"status":"aborted","timestamp":1694289334802,"user_tz":-60,"elapsed":22,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat /proc/cpuinfo"],"metadata":{"id":"LoIfJbBrpt77","executionInfo":{"status":"aborted","timestamp":1694289334802,"user_tz":-60,"elapsed":22,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Laf-u3nwufB6","executionInfo":{"status":"aborted","timestamp":1694289334803,"user_tz":-60,"elapsed":23,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi\n"],"metadata":{"id":"yS-4Yx4bpxQZ","executionInfo":{"status":"aborted","timestamp":1694289334804,"user_tz":-60,"elapsed":24,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat /proc/meminfo\n","with open(\"/proc/meminfo\", \"r\") as f:\n","    lines = f.readlines()\n","\n","for line in lines:\n","    if \"MemTotal\" in line:\n","        print(line.strip())\n","        break\n","\n"],"metadata":{"id":"QYZrXLo5p-t3","executionInfo":{"status":"aborted","timestamp":1694289334804,"user_tz":-60,"elapsed":24,"user":{"displayName":"mehwish mehmood","userId":"03028843311539350970"}}},"execution_count":null,"outputs":[]}]}